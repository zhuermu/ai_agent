{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "Hello\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "!\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " How\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " can\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " I\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " assist\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " today\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "?\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "None\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-AJaSeSRxRvE8nZ9No92gqgJY2XstT', choices=[], created=1729231752, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=19, total_tokens=28, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m****************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os,config\n",
    "\n",
    "OPENAI_API_KEY = config.get_settings().anthropic_api_key\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.gptsapi.net/v1\",\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    max_tokens=1024,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk)\n",
    "   #print(chunk.choices[0].delta.content)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import config, os\n",
    "ANTHROPIC_API_KEY = config.get_settings().anthropic_api_key\n",
    "anthropic_cli = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY, base_url=\"https://api.gptsapi.net\")\n",
    "# anthropic_cli.messages.create(\n",
    "#     model=\"claude-3-5-sonnet-20240620\",\n",
    "#     max_tokens=1024,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "#     ]\n",
    "# )\n",
    "# curl https://api.gptsapi.net/v1/messages -H \"anthropic-version: 2023-06-01\" -H \"content-type: application/json\" -H \"x-api-key: sk-DV450a558242628d9fd82064094108295fbcfe5bdeetlTJT\" -d '\n",
    "# {\n",
    "#   \"model\": \"claude-3-sonnet-20240229\",  \n",
    "#   \"messages\": [\n",
    "#         {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "#     ],\n",
    "#   \"max_tokens\": 1024,\n",
    "#   \"stream\": true\n",
    "# }'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 流式返回存在问题， 无法获取返回值\n",
    "result_str = ''\n",
    "with anthropic_cli.messages.stream(\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    ") as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)\n",
    "        result_str += text\n",
    "result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My favorite novel is \"Moby-Dick\" by Herman Melville. It\\'s an epic tale of man\\'s struggle against the unfathomable forces of nature. The novel\\'s rich symbolism and profound philosophical explorations make it a timeless masterpiece.', additional_kwargs={}, response_metadata={'id': 'msg_bdrk_01Gcv7w6JPeAqdyNZZruowJN', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 40, 'output_tokens': 57}, 'error': {'type': '', 'message': ''}}, id='run-4a5111c2-e8bf-4bd6-8a06-24a9c0c72682-0', usage_metadata={'input_tokens': 40, 'output_tokens': 57, 'total_tokens': 97, 'input_token_details': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "anthropic = RemoteRunnable(\"http://127.0.0.1:8080/anthropic/\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a highly educated person who loves to use big words. \"\n",
    "            + \"You are also concise. Never answer in more than three sentences.\",\n",
    "        ),\n",
    "        (\"human\", \"Tell me about your favorite novel\"),\n",
    "    ]\n",
    ").format_messages()\n",
    "anthropic.invoke(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
